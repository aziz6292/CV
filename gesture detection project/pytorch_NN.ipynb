{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1086c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abdul Aziz\n",
    "# BCSF19A026 \n",
    "# CS Afternoon Add/drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "098b7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f6fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8e357d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12\\AppData\\Local\\Temp\\ipykernel_14360\\2542859864.py:193: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))#, dim=1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "There are four general steps for deep learning models:\n",
    "\n",
    "1.    Prepare the data\n",
    "\n",
    "2.    Build the model\n",
    "\n",
    "3.    Train the model\n",
    "\n",
    "4.    Analyze the model's results\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "Today Lecture\n",
    "\n",
    "1. PyTorch import\n",
    "\n",
    "2. Creat fully connected Network\n",
    "\n",
    "3. Set device\n",
    "\n",
    "4. Hyperparameters\n",
    "\n",
    "5. load data\n",
    "\n",
    "6. Initalize NW\n",
    "\n",
    "7. Load and optimization\n",
    "\n",
    "8. Train NW\n",
    "\n",
    "9. Check accuracy on training and test to see how good our model\n",
    "\n",
    " \n",
    "\n",
    "Resources:\n",
    "\n",
    "1. https://aladdinpersson.medium.com/pytorch-neural-network-tutorial-7e871d6be7c4\n",
    "\n",
    " \n",
    "\n",
    "use the following code and do it for NN instead of ConvNet\n",
    "\n",
    "2. https://cs230.stanford.edu/blog/handsigns/\n",
    "\n",
    " \n",
    "\n",
    "3. #Deeplizard:\n",
    "\n",
    "#https://www.youtube.com/watch?v=v5cngxo4mIg&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG\n",
    "\n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "#First we need will need a couple of different packages\n",
    "\n",
    " \n",
    "import os\n",
    "import torch  #The top-level PyTorch package and tensor library.\n",
    "\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "\n",
    "import torch.nn.functional as F # All functions that don't have any parameters, like relu etc\n",
    "\n",
    "from torch.utils.data import DataLoader # Gives easier dataset managment and creates mini batches\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torchvision.datasets as datasets # Has standard datasets we can import in a nice and easy way\n",
    "\n",
    "import torchvision.transforms as transforms # Perform transformations on dataset (convert numpy to tensor data)\n",
    "\n",
    " \n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SIGNSDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):      \n",
    "        #store filenames\n",
    "        self.filenames = os.listdir(data_dir)\n",
    "        self.filenames = [os.path.join(data_dir, f) for f in self.filenames]\n",
    "\n",
    "        #the first character of the filename contains the label\n",
    "        self.labels = [int(filename.split('/')[-1][0]) for filename in self.filenames]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        #return size of dataset\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #open image, apply transforms and return with label\n",
    "        image = Image.open(self.filenames[idx])  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "#torch.utils.data:          Extract: Access data from source, and create minibatches\n",
    "\n",
    "torch.util.data.DataLoader 1.Extract data from source(and load provide its access) and creat minibatches\n",
    "\n",
    "torch.utils.data.Datasaet  2.If we make our owndataset then import ,and implement its abstract functions=>__getitem__() and __len__().\n",
    "\n",
    "'''\n",
    "\n",
    " \n",
    "train_path='TrainingSet/'\n",
    "test_path='TestingSet/'\n",
    " \n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(28),              # resize the image to 28x28\n",
    "    transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "    transforms.ToTensor()])             # transform it into a PyTorch Tensor\n",
    "\n",
    "train_dataset = SIGNSDataset(train_path, train_transformer)\n",
    "\n",
    "#traing dataset: 60,000 examples\n",
    "\n",
    "train_loader = DataLoader( # 1)extract the dataset from source and 3) load it in form of batches.\n",
    "\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    " \n",
    "\n",
    "# tensor shape: [64 1 28 28] [batchSize noChannels height width]\n",
    "\n",
    " \n",
    "\n",
    "#testing dataset: 10,000 examples\n",
    "\n",
    "test_transformer = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(28),              # resize the image to 28x28\n",
    "    transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "    transforms.ToTensor()])             # transform it into a PyTorch Tensor\n",
    "\n",
    "test_dataset = SIGNSDataset(test_path, test_transformer)\n",
    "\n",
    "   \n",
    "\n",
    "test_loader = DataLoader(\n",
    "\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
    "\n",
    ")\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "class NN(nn.Module):  #1. nn.Module is the base class of all neural network models,\n",
    "\n",
    "                      # we need to extend nn.Module and defined our subclass like NN\n",
    "\n",
    "                      # our model should be the subclass of nn.Module\n",
    "\n",
    "                      #2. define layers of subclass\n",
    "\n",
    "                      #3. implement forward()\n",
    "\n",
    " \n",
    "\n",
    "    def __init__(self, input_size, num_classes): # constructor of NN with its attributes\n",
    "\n",
    "        super(NN, self).__init__() # calling constructor of base class\n",
    "\n",
    "                                    # create two layer NN, first layer with 50 neural and second/output layers with 10 neuraons   \n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 50) #self.fc1.weight.shape =  50,input_size\n",
    "\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "        # callable objects\n",
    "\n",
    "    def forward(self, x):  # we must provid imp of forward () of nn.Module in our subclass\n",
    "\n",
    "        x = F.relu(self.fc1(x)) # //can do F.softmax(self.fc1(x))\n",
    "\n",
    "        #x = self.fc2(x)  #         x = F.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "        x = F.softmax(self.fc2(x))#, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    " \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    " \n",
    "\n",
    "input_size = 784 # 1x28x28 = 784 size of MNIST images (grayscale)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    " \n",
    "\n",
    "# create NN object and move it to device\n",
    "\n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "When we initialize the model the weights and biases\n",
    "\n",
    "of the model will be initialized under the hood of PyTorch\n",
    "\n",
    "and if you want a customized weight initialization it can be added in the NN class.\n",
    "\n",
    "'''\n",
    "\n",
    " \n",
    "\n",
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    " \n",
    "\n",
    "'''\n",
    "\n",
    "The standard loss function for classifications tasks in PyTorch is the CrossEntropyLoss()\n",
    "\n",
    "which applies the softmax functionand negative log likelihood given the predictions\n",
    "\n",
    "of the model and data labels.\n",
    "\n",
    "'''\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    " \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "\n",
    "        # The enumerate() method adds a counter to an iterable\n",
    "\n",
    "        #and returns it (the enumerate object)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "        # Get data to cuda if possible\n",
    "\n",
    "        data = data.to(device=device)\n",
    "\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    " \n",
    "\n",
    "        # Get to correct shape, 1x28x28->784\n",
    "\n",
    "        # -1 will flatten all outer dimensions into one\n",
    "\n",
    "        #print (data.shape) # [64, 1, 28, 28]\n",
    "\n",
    "        #print (targets.shape) # 64 scalar values.\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1) #[64,1x28x28]=[64, 784]\n",
    "\n",
    "        #print (data.shape) #[64,784]\n",
    "\n",
    " \n",
    "\n",
    "        # forward propagation\n",
    "\n",
    "        scores = model(data) #automatically call the forward method,\n",
    "\n",
    "                                #as model is a callable object\n",
    "\n",
    "        loss = criterion(scores, targets) # compute cost/loss on 64 example\n",
    "\n",
    " \n",
    "\n",
    "        # zero previous gradients\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "       \n",
    "\n",
    "        # back-propagation\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    " \n",
    "\n",
    "        # gradient descent or adam step\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    " \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b16e47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: \n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "Got 7 / 64 with accuracy 10.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12\\AppData\\Local\\Temp\\ipykernel_14360\\2542859864.py:193: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))#, dim=1)\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # 1. our model deactivates all the layers (eg.batch normalization/dropout)\n",
    "    with torch.no_grad(): #2.  not make computational graph\n",
    "        for x, y in loader:\n",
    "            #print (x.shape)\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "           \n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            print(x.shape)\n",
    "            #print (y.shape)\n",
    "            \n",
    "            scores = model(x)\n",
    "            print(scores.shape)\n",
    "                      \n",
    "            _, predictions = scores.max(1) #. it return max value and its index, 1 mean see column-wise \n",
    "            \n",
    "            num_correct += (predictions == y).sum() # compare prediction with y, if equal sum them to count the number of same values\n",
    "            num_samples += predictions.size(0)  #64, get no of samples\n",
    "            break  # just to see the results for a single patch\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy\"\n",
    "            f\" {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "        )\n",
    "print (\"Test accuracy: \")\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b7e218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: \n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "Got 8 / 64 with accuracy 12.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12\\AppData\\Local\\Temp\\ipykernel_14360\\2542859864.py:193: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))#, dim=1)\n"
     ]
    }
   ],
   "source": [
    "model.train()# set mode for training,\n",
    "print (\"Train accuracy: \")\n",
    "check_accuracy(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86715851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: \n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "Got 4 / 64 with accuracy 6.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12\\AppData\\Local\\Temp\\ipykernel_14360\\2542859864.py:193: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))#, dim=1)\n"
     ]
    }
   ],
   "source": [
    "print (\"Test accuracy: \")\n",
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "82757b49e65339bd33f08ddd2e40eec658c80b0a07ccc5d275f1adcc0bc451ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
